{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "015c82ed-238d-4228-b6f1-5d66297a5417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "class SimpleCouponPreprocessor:\n",
    "    def __init__(self):\n",
    "        # Frequency columns that should be imputed with 'never'\n",
    "        self.frequency_cols = [\n",
    "            'Bar', 'CoffeeHouse', 'CarryAway',\n",
    "            'RestaurantLessThan20', 'Restaurant20To50'\n",
    "        ]\n",
    "        \n",
    "        # Define forward mappings for categorical variables\n",
    "        self.mappings = {\n",
    "            # Time and Weather\n",
    "            'time': {'7AM': 0, '10AM': 1, '2PM': 2, '6PM': 3, '10PM': 4},\n",
    "            'weather': {'Sunny': 0, 'Rainy': 1, 'Snowy': 2},\n",
    "            'temperature': {30: 0, 55: 1, 80: 2},\n",
    "            'expiration': {'2h': 0, '1d': 1},\n",
    "            \n",
    "            # Demographics\n",
    "            'age': {\n",
    "                'below21': 0, '21': 1, '26': 2, '31': 3,\n",
    "                '36': 4, '41': 5, '46': 6, '50plus': 7\n",
    "            },\n",
    "            'gender': {'Female': 0, 'Male': 1},\n",
    "            'maritalStatus': {\n",
    "                'Single': 0, 'Married partner': 1, 'Unmarried partner': 2,\n",
    "                'Widowed': 3, 'Divorced': 4\n",
    "            },\n",
    "            'education': {\n",
    "                'Some High School': 0,\n",
    "                'High School Graduate': 1,\n",
    "                'Some college - no degree': 2,\n",
    "                'Associates degree': 3,\n",
    "                'Bachelors degree': 4,\n",
    "                'Graduate degree (Masters or Doctorate)': 5\n",
    "            },\n",
    "            'occupation': {\n",
    "                'Unemployed': 0,\n",
    "                'Architecture & Engineering': 1,\n",
    "                'Student': 2,\n",
    "                'Education&Training&Library': 3,\n",
    "                'Healthcare Support': 4,\n",
    "                'Healthcare Practitioners & Technical': 5,\n",
    "                'Sales & Related': 6,\n",
    "                'Management': 7,\n",
    "                'Arts Design Entertainment Sports & Media': 8,\n",
    "                'Computer & Mathematical': 9,\n",
    "                'Life Physical Social Science': 10,\n",
    "                'Personal Care & Service': 11,\n",
    "                'Community & Social Services': 12,\n",
    "                'Office & Administrative Support': 13,\n",
    "                'Construction & Extraction': 14,\n",
    "                'Legal': 15,\n",
    "                'Retired': 16,\n",
    "                'Installation Maintenance & Repair': 17,\n",
    "                'Transportation & Material Moving': 18,\n",
    "                'Business & Financial': 19,\n",
    "                'Protective Service': 20,\n",
    "                'Food Preparation & Serving Related': 21,\n",
    "                'Production Occupations': 22,\n",
    "                'Building & Grounds Cleaning & Maintenance': 23,\n",
    "                'Farming Fishing & Forestry': 24\n",
    "            },\n",
    "            'income': {\n",
    "                'Less than $12500': 0,\n",
    "                '$12500 - $24999': 1,\n",
    "                '$25000 - $37499': 2,\n",
    "                '$37500 - $49999': 3,\n",
    "                '$50000 - $62499': 4,\n",
    "                '$62500 - $74999': 5,\n",
    "                '$75000 - $87499': 6,\n",
    "                '$87500 - $99999': 7,\n",
    "                '$100000 or More': 8\n",
    "            },\n",
    "            \n",
    "            # Location and Context\n",
    "            'destination': {'No Urgent Place': 0, 'Home': 1, 'Work': 2},\n",
    "            'passanger': {'Alone': 0, 'Friend(s)': 1, 'Kid(s)': 2, 'Partner': 3},\n",
    "            'coupon': {\n",
    "                'Restaurant(<20)': 0,\n",
    "                'Coffee House': 1,\n",
    "                'Carry out & Take away': 2,\n",
    "                'Bar': 3,\n",
    "                'Restaurant(20-50)': 4\n",
    "            },\n",
    "            \n",
    "            # Frequency Variables\n",
    "            'Bar': {'never': 0, 'less1': 1, '1~3': 2, '4~8': 3, 'gt8': 4},\n",
    "            'CoffeeHouse': {'never': 0, 'less1': 1, '1~3': 2, '4~8': 3, 'gt8': 4},\n",
    "            'CarryAway': {'never': 0, 'less1': 1, '1~3': 2, '4~8': 3, 'gt8': 4},\n",
    "            'RestaurantLessThan20': {'never': 0, 'less1': 1, '1~3': 2, '4~8': 3, 'gt8': 4},\n",
    "            'Restaurant20To50': {'never': 0, 'less1': 1, '1~3': 2, '4~8': 3, 'gt8': 4}\n",
    "        }\n",
    "        \n",
    "        # Create reverse mappings automatically\n",
    "        self.reverse_mappings = {\n",
    "            col: {v: k for k, v in mapping.items()}\n",
    "            for col, mapping in self.mappings.items()\n",
    "        }\n",
    "\n",
    "    def transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Transform the dataframe using the defined mappings\"\"\"\n",
    "        # Create a copy to avoid modifying the original\n",
    "        df_processed = df.copy()\n",
    "        \n",
    "        # Remove car column if it exists\n",
    "        if 'car' in df_processed.columns:\n",
    "            df_processed = df_processed.drop('car', axis=1)\n",
    "        \n",
    "        # Impute 'never' for frequency columns\n",
    "        for col in self.frequency_cols:\n",
    "            if col in df_processed.columns:\n",
    "                df_processed[col] = df_processed[col].fillna('never')\n",
    "        \n",
    "        # Apply mappings\n",
    "        for col, mapping in self.mappings.items():\n",
    "            if col in df_processed.columns:\n",
    "                df_processed[col] = df_processed[col].map(mapping)\n",
    "        \n",
    "        return df_processed\n",
    "\n",
    "    def reverse_transform(self, df: pd.DataFrame, columns: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "        \"\"\"Reverse transform specified columns back to their original categories\"\"\"\n",
    "        df_reversed = df.copy()\n",
    "        \n",
    "        # If no columns specified, reverse all that have mappings\n",
    "        if columns is None:\n",
    "            columns = list(self.reverse_mappings.keys())\n",
    "        \n",
    "        # Apply reverse mappings for specified columns\n",
    "        for col in columns:\n",
    "            if col in df_reversed.columns and col in self.reverse_mappings:\n",
    "                df_reversed[col] = df_reversed[col].map(self.reverse_mappings[col])\n",
    "        \n",
    "        return df_reversed\n",
    "\n",
    "    def get_mappings(self) -> Dict:\n",
    "        \"\"\"Return the current mappings dictionary\"\"\"\n",
    "        return self.mappings.copy()\n",
    "\n",
    "    def get_reverse_mappings(self) -> Dict:\n",
    "        \"\"\"Return the current reverse mappings dictionary\"\"\"\n",
    "        return self.reverse_mappings.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "add30504-dae8-49f4-bb97-287aa843fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('invehiclecouponrecommendation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b92dfc75-317c-43d6-95a3-45f55c0021bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5684326710816777"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Y'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d37fcc76-68b8-4a10-ac9b-62e5f49086be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unemployed', 'Architecture & Engineering', 'Student',\n",
       "       'Education&Training&Library', 'Healthcare Support',\n",
       "       'Healthcare Practitioners & Technical', 'Sales & Related',\n",
       "       'Management', 'Arts Design Entertainment Sports & Media',\n",
       "       'Computer & Mathematical', 'Life Physical Social Science',\n",
       "       'Personal Care & Service', 'Community & Social Services',\n",
       "       'Office & Administrative Support', 'Construction & Extraction',\n",
       "       'Legal', 'Retired', 'Installation Maintenance & Repair',\n",
       "       'Transportation & Material Moving', 'Business & Financial',\n",
       "       'Protective Service', 'Food Preparation & Serving Related',\n",
       "       'Production Occupations',\n",
       "       'Building & Grounds Cleaning & Maintenance',\n",
       "       'Farming Fishing & Forestry'], dtype=object)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['occupation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "486d29aa-3ea3-4534-86dc-0de9b82455f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocessor = SimpleCouponPreprocessor()\n",
    "transformed_df = preprocessor.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e5975fb6-59eb-4a9e-919f-619e0218aa2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerGroup_ID</th>\n",
       "      <th>Demographic_Behavior</th>\n",
       "      <th>num_observations</th>\n",
       "      <th>original_acceptance_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0-0-0-0-1-0-0-0-0-3-3-0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.409091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0-0-0-0-2-2-8-0-1-2-2-2</td>\n",
       "      <td>21</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0-0-0-0-2-2-8-0-2-3-3-2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0-0-0-0-2-4-0-0-2-1-3-1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0-0-0-0-4-2-1-4-2-1-3-4</td>\n",
       "      <td>22</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerGroup_ID     Demographic_Behavior  num_observations  \\\n",
       "0                 1  0-0-0-0-1-0-0-0-0-3-3-0                22   \n",
       "1                 2  0-0-0-0-2-2-8-0-1-2-2-2                21   \n",
       "2                 3  0-0-0-0-2-2-8-0-2-3-3-2                22   \n",
       "3                 4  0-0-0-0-2-4-0-0-2-1-3-1                22   \n",
       "4                 5  0-0-0-0-4-2-1-4-2-1-3-4                22   \n",
       "\n",
       "   original_acceptance_rate  \n",
       "0                  0.409091  \n",
       "1                  0.809524  \n",
       "2                  0.636364  \n",
       "3                  0.454545  \n",
       "4                  0.681818  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate demographic and behavioral characteristics\n",
    "data = pd.DataFrame()\n",
    "# data['Demographic'] = transformed_df[['gender', 'age', 'maritalStatus', 'has_children', 'education','occupation','income']].astype(str).agg('-'.join, axis=1)\n",
    "# data['Preference_Behavior'] = transformed_df[['Bar', 'CoffeeHouse', 'CarryAway', \n",
    "                                    # 'RestaurantLessThan20', 'Restaurant20To50']].astype(str).agg('-'.join, axis=1)\n",
    "data['Demographic_Behavior'] = transformed_df[['gender', 'age', 'maritalStatus', 'has_children', 'education','occupation','income', 'Bar', 'CoffeeHouse', 'CarryAway', \n",
    "                                    'RestaurantLessThan20', 'Restaurant20To50']].astype(str).agg('-'.join, axis=1)\n",
    "data['Y'] = transformed_df['Y']\n",
    "\n",
    "# Group by 'Demographic' and 'Preference_Behavior', calculate observations and acceptance rate\n",
    "grouped_data = data.groupby(['Demographic_Behavior']).agg(\n",
    "    num_observations=('Y', 'count'),\n",
    "    original_acceptance_rate=('Y', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Add unique IDs for each group\n",
    "grouped_data['CustomerGroup_ID'] = range(1, len(grouped_data) + 1)\n",
    "\n",
    "# Rearrange columns for better readability\n",
    "customer_df = grouped_data[['CustomerGroup_ID', 'Demographic_Behavior',\n",
    "                          # 'Demographic', 'Preference_Behavior', \n",
    "                          'num_observations', 'original_acceptance_rate']]\n",
    "\n",
    "# Display or save the resulting DataFrame\n",
    "customer_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9d64f1d4-774a-44df-bf3e-3c52094b531c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SituationGroup_ID</th>\n",
       "      <th>Situation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0-0-0-0-1-1-1-0-0-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0-0-0-1-1-1-0-0-0-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0-0-0-1-2-1-0-0-0-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0-0-0-1-3-1-0-0-0-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0-0-0-1-4-1-0-0-0-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SituationGroup_ID            Situation\n",
       "0                  1  0-0-0-0-1-1-1-0-0-1\n",
       "1                  2  0-0-0-1-1-1-0-0-0-1\n",
       "2                  3  0-0-0-1-2-1-0-0-0-1\n",
       "3                  4  0-0-0-1-3-1-0-0-0-1\n",
       "4                  5  0-0-0-1-4-1-0-0-0-1"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate demographic and behavioral characteristics\n",
    "data = pd.DataFrame()\n",
    "# data['Demographic'] = transformed_df[['gender', 'age', 'maritalStatus', 'has_children', 'education','occupation','income']].astype(str).agg('-'.join, axis=1)\n",
    "# data['Preference_Behavior'] = transformed_df[['Bar', 'CoffeeHouse', 'CarryAway', \n",
    "                                    # 'RestaurantLessThan20', 'Restaurant20To50']].astype(str).agg('-'.join, axis=1)\n",
    "data['Situation'] = transformed_df[['destination', 'passanger', 'weather', 'temperature',\n",
    "                             'time', 'toCoupon_GEQ5min', 'toCoupon_GEQ15min',\n",
    "                             'toCoupon_GEQ25min', 'direction_same', 'direction_opp']].astype(str).agg('-'.join, axis=1)\n",
    "data['Y'] = transformed_df['Y']\n",
    "\n",
    "# Group by 'Demographic' and 'Preference_Behavior', calculate observations and acceptance rate\n",
    "grouped_data = data.groupby(['Situation']).agg(\n",
    "    num_observations=('Y', 'count'),\n",
    "    acceptance_rate=('Y', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Add unique IDs for each group\n",
    "grouped_data['SituationGroup_ID'] = range(1, len(grouped_data) + 1)\n",
    "\n",
    "# Rearrange columns for better readability\n",
    "situation_df = grouped_data[['SituationGroup_ID', 'Situation']]\n",
    "                          # 'Demographic', 'Preference_Behavior', \n",
    "                          # 'num_observations', 'acceptance_rate']]\n",
    "\n",
    "# Display or save the resulting DataFrame\n",
    "situation_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "474b8b46-330c-429a-bdf1-52a7967c8b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CouponGroup_ID</th>\n",
       "      <th>Coupon Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2-0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CouponGroup_ID Coupon Type\n",
       "0               1         0-0\n",
       "1               2         0-1\n",
       "2               3         1-0\n",
       "3               4         1-1\n",
       "4               5         2-0"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate demographic and behavioral characteristics\n",
    "data = pd.DataFrame()\n",
    "# data['Demographic'] = transformed_df[['gender', 'age', 'maritalStatus', 'has_children', 'education','occupation','income']].astype(str).agg('-'.join, axis=1)\n",
    "# data['Preference_Behavior'] = transformed_df[['Bar', 'CoffeeHouse', 'CarryAway', \n",
    "                                    # 'RestaurantLessThan20', 'Restaurant20To50']].astype(str).agg('-'.join, axis=1)\n",
    "data['Coupon Type'] = transformed_df[['coupon','expiration']].astype(str).agg('-'.join, axis=1)\n",
    "data['Y'] = transformed_df['Y']\n",
    "\n",
    "# Group by 'Demographic' and 'Preference_Behavior', calculate observations and acceptance rate\n",
    "grouped_data = data.groupby(['Coupon Type']).agg(\n",
    "    num_observations=('Y', 'count'),\n",
    "    acceptance_rate=('Y', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Add unique IDs for each group\n",
    "grouped_data['CouponGroup_ID'] = range(1, len(grouped_data) + 1)\n",
    "\n",
    "# Rearrange columns for better readability\n",
    "coupon_df = grouped_data[['CouponGroup_ID', 'Coupon Type']]\n",
    "                          # 'Demographic', 'Preference_Behavior', \n",
    "                          # 'num_observations', 'acceptance_rate']]\n",
    "\n",
    "# Display or save the resulting DataFrame\n",
    "coupon_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "80e048f6-2be4-49d7-9471-38475f91294c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Best Parameters ===\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "=== Cross-validation Results ===\n",
      "Mean CV Score: 0.751 (+/- 0.010)\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[ 688  407]\n",
      " [ 253 1189]]\n",
      "\n",
      "=== ROC AUC Score ===\n",
      "ROC AUC: 0.809\n",
      "\n",
      "=== PR AUC Score ===\n",
      "PR AUC: 0.834\n",
      "\n",
      "=== Top 10 Feature Importance ===\n",
      "                 feature  importance\n",
      "5                 coupon    0.107294\n",
      "12            occupation    0.085538\n",
      "13                income    0.074175\n",
      "8                    age    0.064533\n",
      "15           CoffeeHouse    0.064357\n",
      "4                   time    0.056346\n",
      "14                   Bar    0.053024\n",
      "11             education    0.051886\n",
      "16             CarryAway    0.049802\n",
      "17  RestaurantLessThan20    0.048409\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.63      0.68      1095\n",
      "           1       0.74      0.82      0.78      1442\n",
      "\n",
      "    accuracy                           0.74      2537\n",
      "   macro avg       0.74      0.73      0.73      2537\n",
      "weighted avg       0.74      0.74      0.74      2537\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    roc_curve, precision_recall_curve, auc\n",
    ")\n",
    "\n",
    "# Load the transformed dataset\n",
    "data = transformed_df\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['Y'])  # Assuming 'Y' is the target column\n",
    "y = data['Y']\n",
    "\n",
    "# Get feature names for importance analysis later\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best model and parameters\n",
    "best_rf = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Get cross-validation scores\n",
    "cv_scores = cross_val_score(best_rf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "cv_mean = cv_scores.mean()\n",
    "cv_std = cv_scores.std()\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_rf.predict(X_test)\n",
    "y_pred_proba = best_rf.predict_proba(X_test)\n",
    "\n",
    "# Get confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Get ROC curve data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Get PR curve data\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba[:, 1])\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': best_rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Get classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print all results\n",
    "print(\"\\n=== Best Parameters ===\")\n",
    "print(best_params)\n",
    "\n",
    "print(\"\\n=== Cross-validation Results ===\")\n",
    "print(f\"Mean CV Score: {cv_mean:.3f} (+/- {cv_std * 2:.3f})\")\n",
    "\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\n=== ROC AUC Score ===\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "\n",
    "print(\"\\n=== PR AUC Score ===\")\n",
    "print(f\"PR AUC: {pr_auc:.3f}\")\n",
    "\n",
    "print(\"\\n=== Top 10 Feature Importance ===\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e140197c-7205-4f59-8706-0457be94e5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((567, 4), (121, 2), (10, 2))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df.shape, situation_df.shape, coupon_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3b201d9c-ed85-4b2d-9f66-79e906bba512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine customer groups with existing combinations\n",
    "optimization_matrix = customer_df.merge(situation_df, how='cross')\n",
    "optimization_matrix = optimization_matrix.merge(coupon_df, how='cross')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b154219e-61bf-4421-90f2-8d8697326ee9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CustomerGroup_ID', 'Demographic_Behavior', 'num_observations',\n",
       "       'original_acceptance_rate', 'SituationGroup_ID', 'Situation',\n",
       "       'CouponGroup_ID', 'Coupon Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_matrix.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df81795d-2bd2-4d1b-89f3-4ac43f5a8002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5a14132a-1271-4a29-a8c5-b4faa3d2ee50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reverse map 'Demographic_Behavior' into individual columns\n",
    "demographic_columns = ['gender', 'age', 'maritalStatus', 'has_children', 'education','occupation','income', 'Bar', 'CoffeeHouse', 'CarryAway', \n",
    "                                    'RestaurantLessThan20', 'Restaurant20To50']  # Adjust based on original features\n",
    "situation_columns = ['destination', 'passanger', 'weather', 'temperature',\n",
    "                             'time', 'toCoupon_GEQ5min', 'toCoupon_GEQ15min',\n",
    "                             'toCoupon_GEQ25min', 'direction_same', 'direction_opp']\n",
    "coupon_columns = ['coupon','expiration']\n",
    "\n",
    "optimization_matrix[demographic_columns] = optimization_matrix['Demographic_Behavior'].str.split('-', expand=True)\n",
    "optimization_matrix[situation_columns] = optimization_matrix['Situation'].str.split('-', expand=True)\n",
    "optimization_matrix[coupon_columns] = optimization_matrix['Coupon Type'].str.split('-', expand=True)\n",
    "\n",
    "# Define substrings and specific column names to remove\n",
    "keys_to_match = ['Group_ID', 'num_observations', 'acceptance_rate']\n",
    "additional_columns = ['Demographic_Behavior', 'Situation', 'Coupon Type']\n",
    "\n",
    "# Identify columns to remove dynamically\n",
    "columns_to_remove = [\n",
    "    col for col in optimization_matrix.columns\n",
    "    if any(key in col for key in keys_to_match) or col in additional_columns\n",
    "]\n",
    "\n",
    "# Drop the columns from the DataFrame\n",
    "prediction_features = optimization_matrix.drop(columns=columns_to_remove)\n",
    "prediction_features = prediction_features[X.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "92f1148c-ccea-4dc8-93be-073efc788bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destination</th>\n",
       "      <th>passanger</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>time</th>\n",
       "      <th>coupon</th>\n",
       "      <th>expiration</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>maritalStatus</th>\n",
       "      <th>...</th>\n",
       "      <th>Bar</th>\n",
       "      <th>CoffeeHouse</th>\n",
       "      <th>CarryAway</th>\n",
       "      <th>RestaurantLessThan20</th>\n",
       "      <th>Restaurant20To50</th>\n",
       "      <th>toCoupon_GEQ5min</th>\n",
       "      <th>toCoupon_GEQ15min</th>\n",
       "      <th>toCoupon_GEQ25min</th>\n",
       "      <th>direction_same</th>\n",
       "      <th>direction_opp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686065</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686066</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686067</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686068</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686069</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>686070 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       destination passanger weather temperature time coupon expiration  \\\n",
       "0                0         0       0           0    1      0          0   \n",
       "1                0         0       0           0    1      0          1   \n",
       "2                0         0       0           0    1      1          0   \n",
       "3                0         0       0           0    1      1          1   \n",
       "4                0         0       0           0    1      2          0   \n",
       "...            ...       ...     ...         ...  ...    ...        ...   \n",
       "686065           2         0       2           0    0      2          1   \n",
       "686066           2         0       2           0    0      3          0   \n",
       "686067           2         0       2           0    0      3          1   \n",
       "686068           2         0       2           0    0      4          0   \n",
       "686069           2         0       2           0    0      4          1   \n",
       "\n",
       "       gender age maritalStatus  ... Bar CoffeeHouse CarryAway  \\\n",
       "0           0   0             0  ...   0           0         3   \n",
       "1           0   0             0  ...   0           0         3   \n",
       "2           0   0             0  ...   0           0         3   \n",
       "3           0   0             0  ...   0           0         3   \n",
       "4           0   0             0  ...   0           0         3   \n",
       "...       ...  ..           ...  ...  ..         ...       ...   \n",
       "686065      1   7             4  ...   0           0         0   \n",
       "686066      1   7             4  ...   0           0         0   \n",
       "686067      1   7             4  ...   0           0         0   \n",
       "686068      1   7             4  ...   0           0         0   \n",
       "686069      1   7             4  ...   0           0         0   \n",
       "\n",
       "       RestaurantLessThan20 Restaurant20To50 toCoupon_GEQ5min  \\\n",
       "0                         3                0                1   \n",
       "1                         3                0                1   \n",
       "2                         3                0                1   \n",
       "3                         3                0                1   \n",
       "4                         3                0                1   \n",
       "...                     ...              ...              ...   \n",
       "686065                    0                0                1   \n",
       "686066                    0                0                1   \n",
       "686067                    0                0                1   \n",
       "686068                    0                0                1   \n",
       "686069                    0                0                1   \n",
       "\n",
       "       toCoupon_GEQ15min toCoupon_GEQ25min direction_same direction_opp  \n",
       "0                      1                 0              0             1  \n",
       "1                      1                 0              0             1  \n",
       "2                      1                 0              0             1  \n",
       "3                      1                 0              0             1  \n",
       "4                      1                 0              0             1  \n",
       "...                  ...               ...            ...           ...  \n",
       "686065                 1                 1              0             1  \n",
       "686066                 1                 1              0             1  \n",
       "686067                 1                 1              0             1  \n",
       "686068                 1                 1              0             1  \n",
       "686069                 1                 1              0             1  \n",
       "\n",
       "[686070 rows x 24 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "50b6a2a3-a49e-492e-9af5-23eaa72a84e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerGroup_ID     Demographic_Behavior  num_observations  \\\n",
      "0                 1  0-0-0-0-1-0-0-0-0-3-3-0                22   \n",
      "1                 1  0-0-0-0-1-0-0-0-0-3-3-0                22   \n",
      "2                 1  0-0-0-0-1-0-0-0-0-3-3-0                22   \n",
      "3                 1  0-0-0-0-1-0-0-0-0-3-3-0                22   \n",
      "4                 1  0-0-0-0-1-0-0-0-0-3-3-0                22   \n",
      "\n",
      "   original_acceptance_rate  SituationGroup_ID            Situation  \\\n",
      "0                  0.409091                  1  0-0-0-0-1-1-1-0-0-1   \n",
      "1                  0.409091                  1  0-0-0-0-1-1-1-0-0-1   \n",
      "2                  0.409091                  1  0-0-0-0-1-1-1-0-0-1   \n",
      "3                  0.409091                  1  0-0-0-0-1-1-1-0-0-1   \n",
      "4                  0.409091                  1  0-0-0-0-1-1-1-0-0-1   \n",
      "\n",
      "   CouponGroup_ID Coupon Type gender age  ... temperature time  \\\n",
      "0               1         0-0      0   0  ...           0    1   \n",
      "1               2         0-1      0   0  ...           0    1   \n",
      "2               3         1-0      0   0  ...           0    1   \n",
      "3               4         1-1      0   0  ...           0    1   \n",
      "4               5         2-0      0   0  ...           0    1   \n",
      "\n",
      "  toCoupon_GEQ5min toCoupon_GEQ15min toCoupon_GEQ25min direction_same  \\\n",
      "0                1                 1                 0              0   \n",
      "1                1                 1                 0              0   \n",
      "2                1                 1                 0              0   \n",
      "3                1                 1                 0              0   \n",
      "4                1                 1                 0              0   \n",
      "\n",
      "  direction_opp coupon expiration acceptance_probability  \n",
      "0             1      0          0               0.675000  \n",
      "1             1      0          1               0.630000  \n",
      "2             1      1          0               0.440000  \n",
      "3             1      1          1               0.435714  \n",
      "4             1      2          0               0.545000  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "optimization_matrix['acceptance_probability'] = best_rf.predict_proba(prediction_features)[:, 1]\n",
    "\n",
    "# Display the updated matrix\n",
    "print(optimization_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "a898baae-cf3c-4c99-8bd7-14614587d005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weighted acceptance scores\n",
    "optimization_matrix['weighted_acceptance_score'] = (\n",
    "    optimization_matrix['acceptance_probability'] * optimization_matrix['num_observations']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b55fd275-1023-4a76-9a41-bcaffbb1dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_matrix.to_csv('optimization_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c6ef2d8b-b6df-452e-acfa-04a3411c2ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CustomerGroup_ID  SituationGroup_ID  CouponGroup_ID  \\\n",
      "144231               120                 25               2   \n",
      "357135               296                 19               6   \n",
      "358393               297                 24               4   \n",
      "416731               345                 50               2   \n",
      "\n",
      "        acceptance_probability  num_observations  weighted_acceptance_score  \n",
      "144231                   1.000                22                      22.00  \n",
      "357135                   1.000                22                      22.00  \n",
      "358393                   1.000                22                      22.00  \n",
      "416731                   0.995                34                      33.83  \n"
     ]
    }
   ],
   "source": [
    "from pulp import LpMaximize, LpProblem, LpVariable, lpSum\n",
    "\n",
    "# Define the optimization problem\n",
    "problem = LpProblem(\"Maximize_Weighted_Acceptance\", LpMaximize)\n",
    "\n",
    "# Create binary decision variables for each row in the matrix\n",
    "optimization_matrix['decision_var'] = [\n",
    "    LpVariable(f\"Z_{i}\", cat=\"Binary\") for i in range(len(optimization_matrix))\n",
    "]\n",
    "\n",
    "# Objective: Maximize the total weighted acceptance score\n",
    "problem += lpSum(\n",
    "    var * row['weighted_acceptance_score']\n",
    "    for var, (_, row) in zip(optimization_matrix['decision_var'], optimization_matrix.iterrows())\n",
    ")\n",
    "\n",
    "# Constraint 1: Each CustomerGroup_ID can receive at most one voucher\n",
    "for customer_group in optimization_matrix['CustomerGroup_ID'].unique():\n",
    "    group_rows = optimization_matrix[optimization_matrix['CustomerGroup_ID'] == customer_group]\n",
    "    problem += lpSum(group_rows['decision_var']) <= 1\n",
    "\n",
    "# Constraint 2: Total number of customers covered cannot exceed X\n",
    "X = 100  # Replace with your total voucher limit\n",
    "problem += lpSum(\n",
    "    var * row['num_observations']\n",
    "    for var, (_, row) in zip(optimization_matrix['decision_var'], optimization_matrix.iterrows())\n",
    ") <= X\n",
    "\n",
    "# Solve the optimization problem\n",
    "problem.solve()\n",
    "\n",
    "# Extract results\n",
    "optimization_matrix['allocated'] = [\n",
    "    var.value() for var in optimization_matrix['decision_var']\n",
    "]\n",
    "\n",
    "# Filter the rows with allocated vouchers\n",
    "allocated_vouchers = optimization_matrix[optimization_matrix['allocated'] == 1]\n",
    "\n",
    "# Display the allocated vouchers\n",
    "print(allocated_vouchers[['CustomerGroup_ID', 'SituationGroup_ID', 'CouponGroup_ID', \n",
    "                          'acceptance_probability', 'num_observations', 'weighted_acceptance_score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "84c25764-ce4c-4817-acab-912f57735a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CustomerGroup_ID  SituationGroup_ID  CouponGroup_ID  \\\n",
      "144231               120                 25               2   \n",
      "357135               296                 19               6   \n",
      "358393               297                 24               4   \n",
      "416731               345                 50               2   \n",
      "\n",
      "        acceptance_probability  num_observations  weighted_acceptance_score  \n",
      "144231                   1.000                22                      22.00  \n",
      "357135                   1.000                22                      22.00  \n",
      "358393                   1.000                22                      22.00  \n",
      "416731                   0.995                34                      33.83  \n"
     ]
    }
   ],
   "source": [
    "from pulp import LpMaximize, LpProblem, LpVariable, lpSum\n",
    "\n",
    "# Define the optimization problem\n",
    "problem = LpProblem(\"Maximize_Weighted_Acceptance\", LpMaximize)\n",
    "\n",
    "# Create binary decision variables for each row in the matrix\n",
    "optimization_matrix['decision_var'] = [\n",
    "    LpVariable(f\"Z_{i}\", cat=\"Binary\") for i in range(len(optimization_matrix))\n",
    "]\n",
    "\n",
    "# Objective: Maximize the total weighted acceptance score\n",
    "problem += lpSum(\n",
    "    var * row['weighted_acceptance_score']\n",
    "    for var, (_, row) in zip(optimization_matrix['decision_var'], optimization_matrix.iterrows())\n",
    ")\n",
    "\n",
    "# Constraint 1: Each CustomerGroup_ID can receive at most one voucher\n",
    "for customer_group in optimization_matrix['CustomerGroup_ID'].unique():\n",
    "    group_rows = optimization_matrix[optimization_matrix['CustomerGroup_ID'] == customer_group]\n",
    "    problem += lpSum(group_rows['decision_var']) <= 1\n",
    "\n",
    "# Constraint 2: Total number of customers covered cannot exceed X\n",
    "X = 100  # Replace with your total voucher limit\n",
    "problem += lpSum(\n",
    "    var * row['num_observations']\n",
    "    for var, (_, row) in zip(optimization_matrix['decision_var'], optimization_matrix.iterrows())\n",
    ") <= X\n",
    "\n",
    "# Constraint 3: Limit for Bar coupons\n",
    "bar_rows = optimization_matrix[optimization_matrix['coupon'] == 1]\n",
    "problem += lpSum(\n",
    "    var * row['num_observations']\n",
    "    for var, (_, row) in zip(bar_rows['decision_var'], bar_rows.iterrows())\n",
    ") <= 50\n",
    "\n",
    "# Constraint 4: Limit for Coffee Shop coupons\n",
    "coffee_shop_rows = optimization_matrix[optimization_matrix['coupon'] == 3]\n",
    "problem += lpSum(\n",
    "    var * row['num_observations']\n",
    "    for var, (_, row) in zip(coffee_shop_rows['decision_var'], coffee_shop_rows.iterrows())\n",
    ") <= 50\n",
    "\n",
    "# Solve the optimization problem\n",
    "problem.solve()\n",
    "\n",
    "# Extract results\n",
    "optimization_matrix['allocated'] = [\n",
    "    var.value() for var in optimization_matrix['decision_var']\n",
    "]\n",
    "\n",
    "# Filter the rows with allocated vouchers\n",
    "allocated_vouchers = optimization_matrix[optimization_matrix['allocated'] == 1]\n",
    "\n",
    "# Display the allocated vouchers\n",
    "print(allocated_vouchers[['CustomerGroup_ID', 'SituationGroup_ID', 'CouponGroup_ID', \n",
    "                          'acceptance_probability', 'num_observations', 'weighted_acceptance_score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e93be-2498-46b7-b408-becd9a38f942",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
